# ğŸ“š AI-Powered PDF Question Answering System

This project is a locally hosted **question answering system** that allows users to upload one or more PDF documents and ask natural language questions. It uses a combination of document chunking, semantic search, and a local LLM (LLaMA 3.1â€“8B) to provide accurate and context-specific answers â€” all without needing an internet connection.

---

## ğŸ” Features

- ğŸ“„ Upload one or multiple PDFs
- ğŸ’¬ Ask questions in plain English based on uploaded documents
- ğŸ§  Powered by **LLaMA 3.1 â€“ 8B**, running locally via Ollama
- ğŸ” Fast semantic search using **FAISS vector store**
- ğŸ“Œ Answers are context-aware and grounded in document content
- ğŸ›¡ï¸ Entirely offline â€” 100% local processing

---

## ğŸ§° Tech Stack

| Component            | Tool / Library                                 |
|---------------------|------------------------------------------------|
| LLM Backend          | `llama3:8b` via Ollama                         |
| Document Upload      | Streamlit's `file_uploader`                    |
| Document Loading     | `PyPDFLoader`, `DirectoryLoader` (LangChain)   |
| Text Chunking        | `RecursiveCharacterTextSplitter`              |
| Embedding Model      | `all-MiniLM-L6-v2` (HuggingFace)              |
| Vector Store         | FAISS                                          |
| Retrieval Logic      | LangChainâ€™s `RetrievalQA`                     |
| Chat Interface       | Streamlit                                     |

## ğŸ“¸ Screenshot
